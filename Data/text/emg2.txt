D:\program\Anaconda\envs\comp4190_A2\python.exe C:/Users/Ian/PycharmProjects/comp4190_A2/Code/multilayer_perceptron.py
2020-03-11 13:49:06.917082: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
step: 100, loss: 205.174942, accuracy: 0.234375
step: 200, loss: 202.433151, accuracy: 0.257812
step: 300, loss: 205.585663, accuracy: 0.226562
step: 400, loss: 202.532623, accuracy: 0.273438
step: 500, loss: 204.866425, accuracy: 0.226562
step: 600, loss: 200.349213, accuracy: 0.320312
step: 700, loss: 203.709259, accuracy: 0.375000
step: 800, loss: 205.032806, accuracy: 0.289062
step: 900, loss: 202.084869, accuracy: 0.289062
step: 1000, loss: 205.337128, accuracy: 0.210938
step: 1100, loss: 205.367249, accuracy: 0.187500
step: 1200, loss: 204.619171, accuracy: 0.242188
step: 1300, loss: 203.356232, accuracy: 0.234375
step: 1400, loss: 202.659851, accuracy: 0.273438
step: 1500, loss: 203.356354, accuracy: 0.242188
step: 1600, loss: 200.314850, accuracy: 0.367188
step: 1700, loss: 195.639633, accuracy: 0.351562
step: 1800, loss: 192.064911, accuracy: 0.281250
step: 1900, loss: 183.466949, accuracy: 0.218750
step: 2000, loss: 178.501892, accuracy: 0.359375
Test Accuracy: 0.400000
step: 100, loss: 205.231491, accuracy: 0.218750
step: 200, loss: 205.407196, accuracy: 0.226562
step: 300, loss: 203.659470, accuracy: 0.273438
step: 400, loss: 204.510010, accuracy: 0.250000
step: 500, loss: 205.545776, accuracy: 0.218750
step: 600, loss: 204.936432, accuracy: 0.242188
step: 700, loss: 203.672607, accuracy: 0.257812
step: 800, loss: 204.756775, accuracy: 0.375000
step: 900, loss: 204.708282, accuracy: 0.257812
step: 1000, loss: 204.402725, accuracy: 0.257812
step: 1100, loss: 204.706726, accuracy: 0.265625
step: 1200, loss: 205.195618, accuracy: 0.203125
step: 1300, loss: 204.856781, accuracy: 0.234375
step: 1400, loss: 202.055130, accuracy: 0.265625
step: 1500, loss: 199.632034, accuracy: 0.382812
step: 1600, loss: 229.785522, accuracy: 0.195312
step: 1700, loss: 215.960602, accuracy: 0.242188
step: 1800, loss: 165.650604, accuracy: 0.484375
step: 1900, loss: 164.572037, accuracy: 0.437500
step: 2000, loss: 147.816620, accuracy: 0.515625
Test Accuracy: 0.400000
step: 100, loss: 203.975220, accuracy: 0.265625
step: 200, loss: 202.529999, accuracy: 0.257812
step: 300, loss: 205.100281, accuracy: 0.234375
step: 400, loss: 205.255875, accuracy: 0.226562
step: 500, loss: 204.643707, accuracy: 0.210938
step: 600, loss: 204.417343, accuracy: 0.234375
step: 700, loss: 205.052094, accuracy: 0.281250
step: 800, loss: 204.042145, accuracy: 0.343750
step: 900, loss: 204.659210, accuracy: 0.250000
step: 1000, loss: 203.781265, accuracy: 0.273438
step: 1100, loss: 204.132324, accuracy: 0.234375
step: 1200, loss: 203.886292, accuracy: 0.250000
step: 1300, loss: 196.509842, accuracy: 0.421875
step: 1400, loss: 194.244232, accuracy: 0.351562
step: 1500, loss: 180.869934, accuracy: 0.351562
step: 1600, loss: 264.296021, accuracy: 0.226562
step: 1700, loss: 165.215027, accuracy: 0.312500
step: 1800, loss: 138.818756, accuracy: 0.562500
step: 1900, loss: 134.596298, accuracy: 0.585938
step: 2000, loss: 138.275391, accuracy: 0.507812
Test Accuracy: 0.000000
step: 100, loss: 204.776917, accuracy: 0.226562
step: 200, loss: 205.729767, accuracy: 0.210938
step: 300, loss: 203.406326, accuracy: 0.265625
step: 400, loss: 203.703964, accuracy: 0.273438
step: 500, loss: 205.327881, accuracy: 0.203125
step: 600, loss: 204.636719, accuracy: 0.257812
step: 700, loss: 204.953125, accuracy: 0.242188
step: 800, loss: 205.123901, accuracy: 0.218750
step: 900, loss: 205.027115, accuracy: 0.218750
step: 1000, loss: 204.729767, accuracy: 0.250000
step: 1100, loss: 204.522705, accuracy: 0.203125
step: 1200, loss: 200.260193, accuracy: 0.296875
step: 1300, loss: 203.642426, accuracy: 0.359375
step: 1400, loss: 200.271637, accuracy: 0.367188
step: 1500, loss: 193.693726, accuracy: 0.398438
step: 1600, loss: 195.268661, accuracy: 0.265625
step: 1700, loss: 178.539703, accuracy: 0.328125
step: 1800, loss: 170.493378, accuracy: 0.343750
step: 1900, loss: 156.576660, accuracy: 0.515625
step: 2000, loss: 146.562317, accuracy: 0.500000
Test Accuracy: 0.200000
step: 100, loss: 201.799683, accuracy: 0.265625
step: 200, loss: 204.002335, accuracy: 0.257812
step: 300, loss: 205.151627, accuracy: 0.242188
step: 400, loss: 204.941971, accuracy: 0.250000
step: 500, loss: 205.150696, accuracy: 0.210938
step: 600, loss: 203.199890, accuracy: 0.273438
step: 700, loss: 203.372742, accuracy: 0.289062
step: 800, loss: 205.720016, accuracy: 0.195312
step: 900, loss: 204.787857, accuracy: 0.242188
step: 1000, loss: 205.123779, accuracy: 0.234375
step: 1100, loss: 205.224487, accuracy: 0.234375
step: 1200, loss: 204.768982, accuracy: 0.343750
step: 1300, loss: 203.844879, accuracy: 0.289062
step: 1400, loss: 205.265991, accuracy: 0.195312
step: 1500, loss: 203.501450, accuracy: 0.234375
step: 1600, loss: 199.549759, accuracy: 0.289062
step: 1700, loss: 200.487061, accuracy: 0.296875
step: 1800, loss: 195.564392, accuracy: 0.382812
step: 1900, loss: 200.681244, accuracy: 0.273438
step: 2000, loss: 173.279678, accuracy: 0.406250
Test Accuracy: 0.000000
step: 100, loss: 204.738052, accuracy: 0.226562
step: 200, loss: 204.317688, accuracy: 0.250000
step: 300, loss: 205.479004, accuracy: 0.226562
step: 400, loss: 204.172348, accuracy: 0.242188
step: 500, loss: 205.393829, accuracy: 0.265625
step: 600, loss: 205.517883, accuracy: 0.226562
step: 700, loss: 204.107178, accuracy: 0.265625
step: 800, loss: 204.273880, accuracy: 0.242188
step: 900, loss: 205.242615, accuracy: 0.203125
step: 1000, loss: 203.840668, accuracy: 0.523438
step: 1100, loss: 204.426865, accuracy: 0.265625
step: 1200, loss: 204.807907, accuracy: 0.242188
step: 1300, loss: 204.660568, accuracy: 0.226562
step: 1400, loss: 205.294083, accuracy: 0.250000
step: 1500, loss: 205.110901, accuracy: 0.234375
step: 1600, loss: 202.973267, accuracy: 0.250000
step: 1700, loss: 204.601517, accuracy: 0.273438
step: 1800, loss: 203.490631, accuracy: 0.296875
step: 1900, loss: 203.017059, accuracy: 0.304688
step: 2000, loss: 199.559479, accuracy: 0.312500
Test Accuracy: 0.200000
step: 100, loss: 203.816284, accuracy: 0.242188
step: 200, loss: 204.865997, accuracy: 0.234375
step: 300, loss: 203.936676, accuracy: 0.257812
step: 400, loss: 204.575104, accuracy: 0.242188
step: 500, loss: 202.671478, accuracy: 0.289062
step: 600, loss: 203.751129, accuracy: 0.265625
step: 700, loss: 205.229721, accuracy: 0.250000
step: 800, loss: 204.548584, accuracy: 0.257812
step: 900, loss: 204.075226, accuracy: 0.250000
step: 1000, loss: 205.027512, accuracy: 0.234375
step: 1100, loss: 205.000900, accuracy: 0.218750
step: 1200, loss: 202.965363, accuracy: 0.226562
step: 1300, loss: 204.046875, accuracy: 0.382812
step: 1400, loss: 201.579437, accuracy: 0.312500
step: 1500, loss: 196.803955, accuracy: 0.234375
step: 1600, loss: 204.385132, accuracy: 0.281250
step: 1700, loss: 166.800995, accuracy: 0.406250
step: 1800, loss: 160.000839, accuracy: 0.476562
step: 1900, loss: 177.677002, accuracy: 0.406250
step: 2000, loss: 145.087494, accuracy: 0.476562
Test Accuracy: 0.200000
step: 100, loss: 204.891510, accuracy: 0.242188
step: 200, loss: 203.423111, accuracy: 0.250000
step: 300, loss: 204.924149, accuracy: 0.242188
step: 400, loss: 202.400421, accuracy: 0.335938
step: 500, loss: 205.648697, accuracy: 0.218750
step: 600, loss: 204.399200, accuracy: 0.250000
step: 700, loss: 205.352890, accuracy: 0.242188
step: 800, loss: 204.436615, accuracy: 0.234375
step: 900, loss: 204.392792, accuracy: 0.234375
step: 1000, loss: 204.831970, accuracy: 0.250000
step: 1100, loss: 205.119171, accuracy: 0.210938
step: 1200, loss: 205.500305, accuracy: 0.195312
step: 1300, loss: 205.508865, accuracy: 0.195312
step: 1400, loss: 204.551025, accuracy: 0.226562
step: 1500, loss: 202.559677, accuracy: 0.367188
step: 1600, loss: 202.955322, accuracy: 0.367188
step: 1700, loss: 197.344421, accuracy: 0.296875
step: 1800, loss: 194.223999, accuracy: 0.312500
step: 1900, loss: 182.535950, accuracy: 0.367188
step: 2000, loss: 189.946991, accuracy: 0.250000
Test Accuracy: 0.200000
step: 100, loss: 206.011322, accuracy: 0.218750
step: 200, loss: 204.254150, accuracy: 0.265625
step: 300, loss: 203.679016, accuracy: 0.273438
step: 400, loss: 203.607986, accuracy: 0.257812
step: 500, loss: 203.714340, accuracy: 0.265625
step: 600, loss: 205.700745, accuracy: 0.210938
step: 700, loss: 204.461609, accuracy: 0.242188
step: 800, loss: 205.502136, accuracy: 0.187500
step: 900, loss: 204.407761, accuracy: 0.250000
step: 1000, loss: 206.074081, accuracy: 0.218750
step: 1100, loss: 205.337036, accuracy: 0.234375
step: 1200, loss: 205.275009, accuracy: 0.195312
step: 1300, loss: 205.649261, accuracy: 0.335938
step: 1400, loss: 203.830292, accuracy: 0.281250
step: 1500, loss: 205.527039, accuracy: 0.226562
step: 1600, loss: 205.296509, accuracy: 0.210938
step: 1700, loss: 204.574646, accuracy: 0.226562
step: 1800, loss: 203.875702, accuracy: 0.250000
step: 1900, loss: 202.472839, accuracy: 0.343750
step: 2000, loss: 201.329010, accuracy: 0.351562
Test Accuracy: 0.400000
step: 100, loss: 201.355682, accuracy: 0.289062
step: 200, loss: 205.499908, accuracy: 0.226562
step: 300, loss: 204.002960, accuracy: 0.250000
step: 400, loss: 205.425598, accuracy: 0.234375
step: 500, loss: 205.679535, accuracy: 0.218750
step: 600, loss: 205.597656, accuracy: 0.367188
step: 700, loss: 204.250580, accuracy: 0.218750
step: 800, loss: 204.657135, accuracy: 0.273438
step: 900, loss: 204.396790, accuracy: 0.210938
step: 1000, loss: 204.690262, accuracy: 0.242188
step: 1100, loss: 204.794983, accuracy: 0.226562
step: 1200, loss: 205.122147, accuracy: 0.218750
step: 1300, loss: 200.861664, accuracy: 0.265625
step: 1400, loss: 203.993500, accuracy: 0.289062
step: 1500, loss: 201.100418, accuracy: 0.250000
step: 1600, loss: 200.729980, accuracy: 0.242188
step: 1700, loss: 189.244049, accuracy: 0.343750
step: 1800, loss: 206.846542, accuracy: 0.250000
step: 1900, loss: 180.480820, accuracy: 0.335938
step: 2000, loss: 175.152908, accuracy: 0.367188
Test Accuracy: 0.200000
[0.4000000059604645, 0.4000000059604645, 0.0, 0.20000000298023224, 0.0, 0.20000000298023224, 0.20000000298023224, 0.20000000298023224, 0.4000000059604645, 0.20000000298023224]
average accuracy:0.22000000327825547

Process finished with exit code 0