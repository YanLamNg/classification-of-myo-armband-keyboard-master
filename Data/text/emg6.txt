D:\program\Anaconda\envs\comp4190_A2\python.exe C:/Users/Ian/PycharmProjects/comp4190_A2/Code/multilayer_perceptron.py
2020-03-11 14:45:03.149453: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
step: 100, loss: 204.501862, accuracy: 0.234375
step: 200, loss: 205.425476, accuracy: 0.218750
step: 300, loss: 205.142487, accuracy: 0.210938
step: 400, loss: 201.356567, accuracy: 0.281250
step: 500, loss: 204.661896, accuracy: 0.210938
step: 600, loss: 204.921967, accuracy: 0.210938
step: 700, loss: 204.910233, accuracy: 0.203125
step: 800, loss: 202.006348, accuracy: 0.406250
step: 900, loss: 202.058258, accuracy: 0.351562
step: 1000, loss: 196.721603, accuracy: 0.406250
step: 1100, loss: 196.055511, accuracy: 0.257812
step: 1200, loss: 196.594696, accuracy: 0.226562
step: 1300, loss: 158.669540, accuracy: 0.414062
step: 1400, loss: 153.618484, accuracy: 0.359375
step: 1500, loss: 150.012146, accuracy: 0.468750
step: 1600, loss: 114.596344, accuracy: 0.562500
step: 1700, loss: 115.675194, accuracy: 0.562500
step: 1800, loss: 109.295097, accuracy: 0.609375
step: 1900, loss: 112.475815, accuracy: 0.492188
step: 2000, loss: 114.786606, accuracy: 0.625000
Test Accuracy: 0.400000
step: 100, loss: 202.813080, accuracy: 0.265625
step: 200, loss: 201.820374, accuracy: 0.234375
step: 300, loss: 204.104294, accuracy: 0.250000
step: 400, loss: 204.374207, accuracy: 0.257812
step: 500, loss: 202.296234, accuracy: 0.265625
step: 600, loss: 203.680618, accuracy: 0.273438
step: 700, loss: 204.801422, accuracy: 0.281250
step: 800, loss: 204.934967, accuracy: 0.218750
step: 900, loss: 203.628540, accuracy: 0.273438
step: 1000, loss: 202.957764, accuracy: 0.203125
step: 1100, loss: 200.133789, accuracy: 0.351562
step: 1200, loss: 196.815796, accuracy: 0.289062
step: 1300, loss: 185.270905, accuracy: 0.281250
step: 1400, loss: 180.058456, accuracy: 0.328125
step: 1500, loss: 159.725327, accuracy: 0.406250
step: 1600, loss: 133.543533, accuracy: 0.453125
step: 1700, loss: 161.984985, accuracy: 0.335938
step: 1800, loss: 127.922493, accuracy: 0.539062
step: 1900, loss: 129.204056, accuracy: 0.476562
step: 2000, loss: 143.667236, accuracy: 0.359375
Test Accuracy: 0.400000
step: 100, loss: 204.503494, accuracy: 0.265625
step: 200, loss: 203.082825, accuracy: 0.265625
step: 300, loss: 205.050476, accuracy: 0.242188
step: 400, loss: 205.655579, accuracy: 0.218750
step: 500, loss: 204.453766, accuracy: 0.234375
step: 600, loss: 205.207718, accuracy: 0.234375
step: 700, loss: 203.765488, accuracy: 0.250000
step: 800, loss: 204.618408, accuracy: 0.210938
step: 900, loss: 202.066956, accuracy: 0.273438
step: 1000, loss: 201.865799, accuracy: 0.343750
step: 1100, loss: 196.540466, accuracy: 0.382812
step: 1200, loss: 218.156784, accuracy: 0.281250
step: 1300, loss: 215.779419, accuracy: 0.273438
step: 1400, loss: 166.285522, accuracy: 0.335938
step: 1500, loss: 139.624329, accuracy: 0.500000
step: 1600, loss: 137.436890, accuracy: 0.445312
step: 1700, loss: 124.732216, accuracy: 0.468750
step: 1800, loss: 114.696106, accuracy: 0.453125
step: 1900, loss: 133.339600, accuracy: 0.437500
step: 2000, loss: 84.877258, accuracy: 0.750000
Test Accuracy: 0.600000
step: 100, loss: 202.979218, accuracy: 0.273438
step: 200, loss: 204.600922, accuracy: 0.250000
step: 300, loss: 204.885406, accuracy: 0.250000
step: 400, loss: 203.254608, accuracy: 0.265625
step: 500, loss: 203.677826, accuracy: 0.250000
step: 600, loss: 204.852966, accuracy: 0.218750
step: 700, loss: 205.600983, accuracy: 0.218750
step: 800, loss: 203.517883, accuracy: 0.234375
step: 900, loss: 201.571320, accuracy: 0.273438
step: 1000, loss: 200.864868, accuracy: 0.382812
step: 1100, loss: 188.573486, accuracy: 0.445312
step: 1200, loss: 180.286453, accuracy: 0.351562
step: 1300, loss: 166.597565, accuracy: 0.265625
step: 1400, loss: 142.707062, accuracy: 0.515625
step: 1500, loss: 152.364182, accuracy: 0.382812
step: 1600, loss: 122.023315, accuracy: 0.453125
step: 1700, loss: 120.826080, accuracy: 0.601562
step: 1800, loss: 127.199860, accuracy: 0.554688
step: 1900, loss: 111.861351, accuracy: 0.523438
step: 2000, loss: 106.315598, accuracy: 0.664062
Test Accuracy: 0.600000
step: 100, loss: 203.649139, accuracy: 0.257812
step: 200, loss: 202.905533, accuracy: 0.265625
step: 300, loss: 204.127014, accuracy: 0.250000
step: 400, loss: 205.579880, accuracy: 0.203125
step: 500, loss: 205.323853, accuracy: 0.218750
step: 600, loss: 204.913177, accuracy: 0.226562
step: 700, loss: 204.171082, accuracy: 0.273438
step: 800, loss: 200.373016, accuracy: 0.320312
step: 900, loss: 204.394653, accuracy: 0.195312
step: 1000, loss: 204.422150, accuracy: 0.406250
step: 1100, loss: 203.187500, accuracy: 0.250000
step: 1200, loss: 200.694794, accuracy: 0.414062
step: 1300, loss: 194.452271, accuracy: 0.398438
step: 1400, loss: 177.461151, accuracy: 0.406250
step: 1500, loss: 230.195084, accuracy: 0.265625
step: 1600, loss: 130.384857, accuracy: 0.546875
step: 1700, loss: 162.791580, accuracy: 0.359375
step: 1800, loss: 102.359482, accuracy: 0.671875
step: 1900, loss: 89.402603, accuracy: 0.617188
step: 2000, loss: 89.461853, accuracy: 0.664062
Test Accuracy: 0.200000
step: 100, loss: 205.527603, accuracy: 0.218750
step: 200, loss: 205.294617, accuracy: 0.226562
step: 300, loss: 202.932251, accuracy: 0.226562
step: 400, loss: 204.271317, accuracy: 0.234375
step: 500, loss: 203.921371, accuracy: 0.257812
step: 600, loss: 204.794678, accuracy: 0.429688
step: 700, loss: 204.342346, accuracy: 0.250000
step: 800, loss: 204.295959, accuracy: 0.234375
step: 900, loss: 202.646942, accuracy: 0.250000
step: 1000, loss: 198.961304, accuracy: 0.296875
step: 1100, loss: 186.404343, accuracy: 0.273438
step: 1200, loss: 212.567352, accuracy: 0.234375
step: 1300, loss: 158.891663, accuracy: 0.312500
step: 1400, loss: 135.657532, accuracy: 0.507812
step: 1500, loss: 130.642761, accuracy: 0.468750
step: 1600, loss: 118.289886, accuracy: 0.515625
step: 1700, loss: 116.407066, accuracy: 0.507812
step: 1800, loss: 111.427025, accuracy: 0.625000
step: 1900, loss: 97.206009, accuracy: 0.726562
step: 2000, loss: 89.216881, accuracy: 0.734375
Test Accuracy: 0.200000
step: 100, loss: 205.553406, accuracy: 0.218750
step: 200, loss: 204.982178, accuracy: 0.242188
step: 300, loss: 204.988922, accuracy: 0.218750
step: 400, loss: 204.676270, accuracy: 0.234375
step: 500, loss: 205.512695, accuracy: 0.210938
step: 600, loss: 205.484390, accuracy: 0.226562
step: 700, loss: 203.847015, accuracy: 0.234375
step: 800, loss: 204.357086, accuracy: 0.234375
step: 900, loss: 203.711243, accuracy: 0.218750
step: 1000, loss: 203.114914, accuracy: 0.226562
step: 1100, loss: 202.386383, accuracy: 0.359375
step: 1200, loss: 197.000549, accuracy: 0.265625
step: 1300, loss: 185.080978, accuracy: 0.398438
step: 1400, loss: 157.198807, accuracy: 0.367188
step: 1500, loss: 155.074326, accuracy: 0.445312
step: 1600, loss: 144.870972, accuracy: 0.351562
step: 1700, loss: 130.798065, accuracy: 0.421875
step: 1800, loss: 131.254135, accuracy: 0.500000
step: 1900, loss: 214.329773, accuracy: 0.289062
step: 2000, loss: 121.950966, accuracy: 0.484375
Test Accuracy: 0.600000
step: 100, loss: 205.794800, accuracy: 0.210938
step: 200, loss: 203.422180, accuracy: 0.265625
step: 300, loss: 204.560364, accuracy: 0.226562
step: 400, loss: 205.168503, accuracy: 0.218750
step: 500, loss: 204.686920, accuracy: 0.312500
step: 600, loss: 205.205948, accuracy: 0.226562
step: 700, loss: 202.326080, accuracy: 0.265625
step: 800, loss: 203.699890, accuracy: 0.257812
step: 900, loss: 201.916245, accuracy: 0.289062
step: 1000, loss: 200.405304, accuracy: 0.250000
step: 1100, loss: 193.967224, accuracy: 0.257812
step: 1200, loss: 198.053192, accuracy: 0.281250
step: 1300, loss: 181.636124, accuracy: 0.312500
step: 1400, loss: 151.714447, accuracy: 0.375000
step: 1500, loss: 141.791382, accuracy: 0.460938
step: 1600, loss: 126.765182, accuracy: 0.492188
step: 1700, loss: 328.870422, accuracy: 0.257812
step: 1800, loss: 109.650696, accuracy: 0.648438
step: 1900, loss: 87.900719, accuracy: 0.820312
step: 2000, loss: 90.726234, accuracy: 0.648438
Test Accuracy: 0.600000
step: 100, loss: 203.926620, accuracy: 0.257812
step: 200, loss: 204.421417, accuracy: 0.242188
step: 300, loss: 204.851028, accuracy: 0.242188
step: 400, loss: 204.931961, accuracy: 0.250000
step: 500, loss: 204.466278, accuracy: 0.234375
step: 600, loss: 205.397476, accuracy: 0.218750
step: 700, loss: 204.601761, accuracy: 0.335938
step: 800, loss: 201.854614, accuracy: 0.468750
step: 900, loss: 202.036270, accuracy: 0.226562
step: 1000, loss: 192.989777, accuracy: 0.359375
step: 1100, loss: 185.113434, accuracy: 0.265625
step: 1200, loss: 180.179611, accuracy: 0.242188
step: 1300, loss: 144.382004, accuracy: 0.468750
step: 1400, loss: 128.460175, accuracy: 0.507812
step: 1500, loss: 139.356842, accuracy: 0.468750
step: 1600, loss: 207.981445, accuracy: 0.296875
step: 1700, loss: 123.601280, accuracy: 0.578125
step: 1800, loss: 142.366852, accuracy: 0.273438
step: 1900, loss: 183.960144, accuracy: 0.281250
step: 2000, loss: 223.410278, accuracy: 0.320312
Test Accuracy: 0.400000
step: 100, loss: 201.605774, accuracy: 0.273438
step: 200, loss: 205.098389, accuracy: 0.226562
step: 300, loss: 204.185272, accuracy: 0.242188
step: 400, loss: 203.092590, accuracy: 0.289062
step: 500, loss: 205.488815, accuracy: 0.218750
step: 600, loss: 205.183670, accuracy: 0.210938
step: 700, loss: 203.516830, accuracy: 0.273438
step: 800, loss: 204.151581, accuracy: 0.218750
step: 900, loss: 203.099945, accuracy: 0.265625
step: 1000, loss: 202.981247, accuracy: 0.257812
step: 1100, loss: 198.272186, accuracy: 0.226562
step: 1200, loss: 187.087204, accuracy: 0.468750
step: 1300, loss: 178.133896, accuracy: 0.335938
step: 1400, loss: 174.141937, accuracy: 0.320312
step: 1500, loss: 152.813278, accuracy: 0.468750
step: 1600, loss: 127.099426, accuracy: 0.476562
step: 1700, loss: 134.195160, accuracy: 0.460938
step: 1800, loss: 118.776222, accuracy: 0.554688
step: 1900, loss: 116.299004, accuracy: 0.570312
step: 2000, loss: 102.132217, accuracy: 0.687500
Test Accuracy: 0.400000
[0.4000000059604645, 0.4000000059604645, 0.6000000238418579, 0.6000000238418579, 0.20000000298023224, 0.20000000298023224, 0.6000000238418579, 0.6000000238418579, 0.4000000059604645, 0.4000000059604645]
average accuracy:0.4400000125169754

Process finished with exit code 0
