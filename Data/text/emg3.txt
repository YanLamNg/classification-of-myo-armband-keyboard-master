D:\program\Anaconda\envs\comp4190_A2\python.exe C:/Users/Ian/PycharmProjects/comp4190_A2/Code/multilayer_perceptron.py
2020-03-11 13:56:23.859541: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
step: 100, loss: 202.514954, accuracy: 0.257812
step: 200, loss: 203.389175, accuracy: 0.265625
step: 300, loss: 204.540298, accuracy: 0.234375
step: 400, loss: 204.378922, accuracy: 0.335938
step: 500, loss: 204.837585, accuracy: 0.210938
step: 600, loss: 203.953323, accuracy: 0.429688
step: 700, loss: 199.515564, accuracy: 0.250000
step: 800, loss: 194.747772, accuracy: 0.257812
step: 900, loss: 153.331482, accuracy: 0.429688
step: 1000, loss: 143.569611, accuracy: 0.453125
step: 1100, loss: 134.231232, accuracy: 0.578125
step: 1200, loss: 128.576385, accuracy: 0.445312
step: 1300, loss: 126.507614, accuracy: 0.523438
step: 1400, loss: 131.139404, accuracy: 0.585938
step: 1500, loss: 116.170830, accuracy: 0.570312
step: 1600, loss: 112.428162, accuracy: 0.539062
step: 1700, loss: 114.093910, accuracy: 0.648438
step: 1800, loss: 186.771072, accuracy: 0.375000
step: 1900, loss: 111.006943, accuracy: 0.531250
step: 2000, loss: 107.449944, accuracy: 0.625000
Test Accuracy: 0.200000
step: 100, loss: 202.271164, accuracy: 0.257812
step: 200, loss: 204.194000, accuracy: 0.234375
step: 300, loss: 204.821289, accuracy: 0.234375
step: 400, loss: 204.514771, accuracy: 0.250000
step: 500, loss: 204.224396, accuracy: 0.234375
step: 600, loss: 201.829666, accuracy: 0.234375
step: 700, loss: 193.221619, accuracy: 0.359375
step: 800, loss: 218.919052, accuracy: 0.226562
step: 900, loss: 136.166595, accuracy: 0.515625
step: 1000, loss: 130.079590, accuracy: 0.484375
step: 1100, loss: 128.415024, accuracy: 0.507812
step: 1200, loss: 127.670746, accuracy: 0.523438
step: 1300, loss: 135.571747, accuracy: 0.570312
step: 1400, loss: 129.327591, accuracy: 0.507812
step: 1500, loss: 128.654236, accuracy: 0.507812
step: 1600, loss: 126.805992, accuracy: 0.492188
step: 1700, loss: 111.205620, accuracy: 0.531250
step: 1800, loss: 117.368874, accuracy: 0.546875
step: 1900, loss: 124.092354, accuracy: 0.531250
step: 2000, loss: 121.912407, accuracy: 0.460938
Test Accuracy: 0.400000
step: 100, loss: 204.790680, accuracy: 0.234375
step: 200, loss: 204.137970, accuracy: 0.242188
step: 300, loss: 202.870300, accuracy: 0.242188
step: 400, loss: 204.721176, accuracy: 0.226562
step: 500, loss: 204.830643, accuracy: 0.304688
step: 600, loss: 203.029282, accuracy: 0.218750
step: 700, loss: 196.182739, accuracy: 0.406250
step: 800, loss: 172.682251, accuracy: 0.382812
step: 900, loss: 145.441559, accuracy: 0.460938
step: 1000, loss: 135.304977, accuracy: 0.507812
step: 1100, loss: 137.607101, accuracy: 0.507812
step: 1200, loss: 131.807098, accuracy: 0.437500
step: 1300, loss: 128.928360, accuracy: 0.523438
step: 1400, loss: 126.171822, accuracy: 0.492188
step: 1500, loss: 145.631241, accuracy: 0.429688
step: 1600, loss: 128.479187, accuracy: 0.406250
step: 1700, loss: 120.682472, accuracy: 0.515625
step: 1800, loss: 125.979042, accuracy: 0.515625
step: 1900, loss: 109.259491, accuracy: 0.640625
step: 2000, loss: 117.320343, accuracy: 0.562500
Test Accuracy: 0.200000
step: 100, loss: 200.344025, accuracy: 0.273438
step: 200, loss: 204.664856, accuracy: 0.226562
step: 300, loss: 203.356415, accuracy: 0.265625
step: 400, loss: 205.238617, accuracy: 0.210938
step: 500, loss: 204.668594, accuracy: 0.257812
step: 600, loss: 200.561157, accuracy: 0.296875
step: 700, loss: 200.577240, accuracy: 0.429688
step: 800, loss: 191.245087, accuracy: 0.242188
step: 900, loss: 162.519394, accuracy: 0.328125
step: 1000, loss: 139.331268, accuracy: 0.492188
step: 1100, loss: 133.237320, accuracy: 0.531250
step: 1200, loss: 143.015610, accuracy: 0.406250
step: 1300, loss: 137.843506, accuracy: 0.492188
step: 1400, loss: 127.511520, accuracy: 0.554688
step: 1500, loss: 118.667442, accuracy: 0.500000
step: 1600, loss: 124.198044, accuracy: 0.539062
step: 1700, loss: 135.670868, accuracy: 0.492188
step: 1800, loss: 117.513229, accuracy: 0.554688
step: 1900, loss: 117.827850, accuracy: 0.656250
step: 2000, loss: 116.024902, accuracy: 0.515625
Test Accuracy: 0.400000
step: 100, loss: 204.749939, accuracy: 0.234375
step: 200, loss: 197.704895, accuracy: 0.328125
step: 300, loss: 205.414124, accuracy: 0.390625
step: 400, loss: 204.079605, accuracy: 0.210938
step: 500, loss: 202.908112, accuracy: 0.273438
step: 600, loss: 203.092361, accuracy: 0.304688
step: 700, loss: 196.016876, accuracy: 0.398438
step: 800, loss: 187.369415, accuracy: 0.218750
step: 900, loss: 161.003906, accuracy: 0.335938
step: 1000, loss: 157.922699, accuracy: 0.328125
step: 1100, loss: 141.988861, accuracy: 0.382812
step: 1200, loss: 138.219818, accuracy: 0.414062
step: 1300, loss: 133.148605, accuracy: 0.593750
step: 1400, loss: 125.520721, accuracy: 0.546875
step: 1500, loss: 129.879837, accuracy: 0.515625
step: 1600, loss: 118.439682, accuracy: 0.664062
step: 1700, loss: 118.564667, accuracy: 0.539062
step: 1800, loss: 116.124878, accuracy: 0.601562
step: 1900, loss: 115.938995, accuracy: 0.585938
step: 2000, loss: 125.944656, accuracy: 0.546875
Test Accuracy: 0.200000
step: 100, loss: 203.765671, accuracy: 0.242188
step: 200, loss: 204.444641, accuracy: 0.257812
step: 300, loss: 202.851151, accuracy: 0.265625
step: 400, loss: 204.177704, accuracy: 0.242188
step: 500, loss: 204.330688, accuracy: 0.210938
step: 600, loss: 202.547516, accuracy: 0.226562
step: 700, loss: 192.099625, accuracy: 0.390625
step: 800, loss: 157.948364, accuracy: 0.445312
step: 900, loss: 143.738724, accuracy: 0.445312
step: 1000, loss: 152.300629, accuracy: 0.460938
step: 1100, loss: 141.386871, accuracy: 0.468750
step: 1200, loss: 130.547501, accuracy: 0.562500
step: 1300, loss: 125.300735, accuracy: 0.531250
step: 1400, loss: 137.103088, accuracy: 0.492188
step: 1500, loss: 122.071838, accuracy: 0.585938
step: 1600, loss: 131.022812, accuracy: 0.476562
step: 1700, loss: 150.869400, accuracy: 0.468750
step: 1800, loss: 110.299843, accuracy: 0.570312
step: 1900, loss: 117.820290, accuracy: 0.515625
step: 2000, loss: 130.407867, accuracy: 0.531250
Test Accuracy: 0.400000
step: 100, loss: 203.580673, accuracy: 0.265625
step: 200, loss: 204.177094, accuracy: 0.242188
step: 300, loss: 203.943283, accuracy: 0.234375
step: 400, loss: 202.367188, accuracy: 0.281250
step: 500, loss: 202.706360, accuracy: 0.265625
step: 600, loss: 202.894836, accuracy: 0.257812
step: 700, loss: 198.299225, accuracy: 0.320312
step: 800, loss: 207.258713, accuracy: 0.242188
step: 900, loss: 154.294617, accuracy: 0.468750
step: 1000, loss: 145.298584, accuracy: 0.507812
step: 1100, loss: 137.832092, accuracy: 0.500000
step: 1200, loss: 141.084137, accuracy: 0.492188
step: 1300, loss: 137.282990, accuracy: 0.351562
step: 1400, loss: 151.334305, accuracy: 0.382812
step: 1500, loss: 135.773483, accuracy: 0.398438
step: 1600, loss: 146.138214, accuracy: 0.468750
step: 1700, loss: 125.337486, accuracy: 0.617188
step: 1800, loss: 132.675339, accuracy: 0.460938
step: 1900, loss: 125.927139, accuracy: 0.476562
step: 2000, loss: 116.637550, accuracy: 0.593750
Test Accuracy: 0.600000
step: 100, loss: 204.473541, accuracy: 0.226562
step: 200, loss: 204.130127, accuracy: 0.234375
step: 300, loss: 204.230148, accuracy: 0.242188
step: 400, loss: 205.166534, accuracy: 0.226562
step: 500, loss: 204.414673, accuracy: 0.218750
step: 600, loss: 203.508179, accuracy: 0.265625
step: 700, loss: 201.662827, accuracy: 0.242188
step: 800, loss: 184.059021, accuracy: 0.328125
step: 900, loss: 162.244278, accuracy: 0.421875
step: 1000, loss: 155.484955, accuracy: 0.375000
step: 1100, loss: 149.494873, accuracy: 0.335938
step: 1200, loss: 137.834900, accuracy: 0.539062
step: 1300, loss: 135.873138, accuracy: 0.398438
step: 1400, loss: 131.194504, accuracy: 0.546875
step: 1500, loss: 133.863525, accuracy: 0.406250
step: 1600, loss: 143.703659, accuracy: 0.539062
step: 1700, loss: 134.954971, accuracy: 0.500000
step: 1800, loss: 125.570862, accuracy: 0.570312
step: 1900, loss: 125.014481, accuracy: 0.500000
step: 2000, loss: 127.586548, accuracy: 0.609375
Test Accuracy: 0.800000
step: 100, loss: 204.743973, accuracy: 0.242188
step: 200, loss: 205.334412, accuracy: 0.226562
step: 300, loss: 204.453171, accuracy: 0.234375
step: 400, loss: 204.992615, accuracy: 0.226562
step: 500, loss: 203.744568, accuracy: 0.234375
step: 600, loss: 201.527344, accuracy: 0.265625
step: 700, loss: 196.041336, accuracy: 0.304688
step: 800, loss: 178.293945, accuracy: 0.343750
step: 900, loss: 148.743958, accuracy: 0.453125
step: 1000, loss: 148.216400, accuracy: 0.492188
step: 1100, loss: 144.200668, accuracy: 0.445312
step: 1200, loss: 143.449600, accuracy: 0.523438
step: 1300, loss: 148.322571, accuracy: 0.414062
step: 1400, loss: 152.721481, accuracy: 0.328125
step: 1500, loss: 138.202438, accuracy: 0.515625
step: 1600, loss: 124.818115, accuracy: 0.539062
step: 1700, loss: 126.900604, accuracy: 0.414062
step: 1800, loss: 132.754959, accuracy: 0.554688
step: 1900, loss: 133.637405, accuracy: 0.476562
step: 2000, loss: 122.058990, accuracy: 0.562500
Test Accuracy: 0.400000
step: 100, loss: 204.774506, accuracy: 0.242188
step: 200, loss: 203.353851, accuracy: 0.250000
step: 300, loss: 200.420212, accuracy: 0.296875
step: 400, loss: 205.565170, accuracy: 0.210938
step: 500, loss: 203.361160, accuracy: 0.320312
step: 600, loss: 202.198517, accuracy: 0.242188
step: 700, loss: 200.208359, accuracy: 0.328125
step: 800, loss: 181.973572, accuracy: 0.359375
step: 900, loss: 149.342926, accuracy: 0.476562
step: 1000, loss: 147.026154, accuracy: 0.468750
step: 1100, loss: 139.569290, accuracy: 0.515625
step: 1200, loss: 125.626663, accuracy: 0.531250
step: 1300, loss: 139.977051, accuracy: 0.445312
step: 1400, loss: 136.021332, accuracy: 0.476562
step: 1500, loss: 145.694611, accuracy: 0.492188
step: 1600, loss: 135.314728, accuracy: 0.500000
step: 1700, loss: 134.059570, accuracy: 0.507812
step: 1800, loss: 134.380173, accuracy: 0.406250
step: 1900, loss: 138.972504, accuracy: 0.484375
step: 2000, loss: 122.866409, accuracy: 0.546875
Test Accuracy: 0.800000
[0.20000000298023224, 0.4000000059604645, 0.20000000298023224, 0.4000000059604645, 0.20000000298023224, 0.4000000059604645, 0.6000000238418579, 0.800000011920929, 0.4000000059604645, 0.800000011920929]
average accuracy:0.44000000804662703

Process finished with exit code 0
