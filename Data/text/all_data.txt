D:\program\Anaconda\envs\comp4190_A2\python.exe D:/pycharm_project/comp4190_A2/Code/multilayer_perceptron.py
2020-03-12 17:33:35.915056: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
step: 100, loss: 202.100128, accuracy: 0.250000
step: 200, loss: 191.485519, accuracy: 0.664062
step: 300, loss: 95.289642, accuracy: 0.796875
step: 400, loss: 31.569803, accuracy: 0.976562
step: 500, loss: 7.357449, accuracy: 0.992188
step: 600, loss: 2.707710, accuracy: 1.000000
step: 700, loss: 1.841631, accuracy: 1.000000
step: 800, loss: 1.127120, accuracy: 1.000000
step: 900, loss: 0.884065, accuracy: 1.000000
step: 1000, loss: 0.730490, accuracy: 1.000000
step: 1100, loss: 0.641722, accuracy: 1.000000
step: 1200, loss: 0.483932, accuracy: 1.000000
step: 1300, loss: 0.471075, accuracy: 1.000000
step: 1400, loss: 0.403724, accuracy: 1.000000
step: 1500, loss: 0.329679, accuracy: 1.000000
step: 1600, loss: 0.201716, accuracy: 1.000000
step: 1700, loss: 0.267943, accuracy: 1.000000
step: 1800, loss: 0.250320, accuracy: 1.000000
step: 1900, loss: 0.201572, accuracy: 1.000000
step: 2000, loss: 0.177807, accuracy: 1.000000
Test Accuracy: 0.600000
step: 100, loss: 201.607544, accuracy: 0.484375
step: 200, loss: 190.562973, accuracy: 0.359375
step: 300, loss: 118.601578, accuracy: 0.562500
step: 400, loss: 30.335732, accuracy: 1.000000
step: 500, loss: 8.820087, accuracy: 1.000000
step: 600, loss: 3.110435, accuracy: 1.000000
step: 700, loss: 2.190689, accuracy: 1.000000
step: 800, loss: 1.466269, accuracy: 1.000000
step: 900, loss: 0.995088, accuracy: 1.000000
step: 1000, loss: 0.674191, accuracy: 1.000000
step: 1100, loss: 0.610253, accuracy: 1.000000
step: 1200, loss: 0.473599, accuracy: 1.000000
step: 1300, loss: 0.472744, accuracy: 1.000000
step: 1400, loss: 0.373393, accuracy: 1.000000
step: 1500, loss: 0.286423, accuracy: 1.000000
step: 1600, loss: 0.308685, accuracy: 1.000000
step: 1700, loss: 0.309820, accuracy: 1.000000
step: 1800, loss: 0.244344, accuracy: 1.000000
step: 1900, loss: 0.233035, accuracy: 1.000000
step: 2000, loss: 0.209643, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 196.702850, accuracy: 0.296875
step: 200, loss: 189.939774, accuracy: 0.281250
step: 300, loss: 87.960434, accuracy: 0.656250
step: 400, loss: 16.059570, accuracy: 1.000000
step: 500, loss: 4.162923, accuracy: 1.000000
step: 600, loss: 1.783508, accuracy: 1.000000
step: 700, loss: 1.404628, accuracy: 1.000000
step: 800, loss: 0.922972, accuracy: 1.000000
step: 900, loss: 0.826258, accuracy: 1.000000
step: 1000, loss: 0.577553, accuracy: 1.000000
step: 1100, loss: 0.538597, accuracy: 1.000000
step: 1200, loss: 0.476520, accuracy: 1.000000
step: 1300, loss: 0.346415, accuracy: 1.000000
step: 1400, loss: 0.311094, accuracy: 1.000000
step: 1500, loss: 0.284369, accuracy: 1.000000
step: 1600, loss: 0.276456, accuracy: 1.000000
step: 1700, loss: 0.272675, accuracy: 1.000000
step: 1800, loss: 0.246883, accuracy: 1.000000
step: 1900, loss: 0.204386, accuracy: 1.000000
step: 2000, loss: 0.229507, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 199.850800, accuracy: 0.289062
step: 200, loss: 196.300140, accuracy: 0.312500
step: 300, loss: 106.007820, accuracy: 0.773438
step: 400, loss: 20.998512, accuracy: 1.000000
step: 500, loss: 4.896445, accuracy: 1.000000
step: 600, loss: 2.322103, accuracy: 1.000000
step: 700, loss: 1.736771, accuracy: 1.000000
step: 800, loss: 1.092791, accuracy: 1.000000
step: 900, loss: 1.041171, accuracy: 1.000000
step: 1000, loss: 0.755820, accuracy: 1.000000
step: 1100, loss: 0.662264, accuracy: 1.000000
step: 1200, loss: 0.411184, accuracy: 1.000000
step: 1300, loss: 0.364868, accuracy: 1.000000
step: 1400, loss: 0.356467, accuracy: 1.000000
step: 1500, loss: 0.359788, accuracy: 1.000000
step: 1600, loss: 0.268373, accuracy: 1.000000
step: 1700, loss: 0.255510, accuracy: 1.000000
step: 1800, loss: 0.251542, accuracy: 1.000000
step: 1900, loss: 0.202176, accuracy: 1.000000
step: 2000, loss: 0.252491, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 202.074707, accuracy: 0.234375
step: 200, loss: 194.073700, accuracy: 0.273438
step: 300, loss: 99.454552, accuracy: 0.890625
step: 400, loss: 51.927727, accuracy: 0.773438
step: 500, loss: 6.435836, accuracy: 1.000000
step: 600, loss: 2.901849, accuracy: 1.000000
step: 700, loss: 1.928524, accuracy: 1.000000
step: 800, loss: 1.127501, accuracy: 1.000000
step: 900, loss: 0.933468, accuracy: 1.000000
step: 1000, loss: 0.641130, accuracy: 1.000000
step: 1100, loss: 0.613054, accuracy: 1.000000
step: 1200, loss: 0.532993, accuracy: 1.000000
step: 1300, loss: 0.377075, accuracy: 1.000000
step: 1400, loss: 0.290456, accuracy: 1.000000
step: 1500, loss: 0.319486, accuracy: 1.000000
step: 1600, loss: 0.275221, accuracy: 1.000000
step: 1700, loss: 0.265898, accuracy: 1.000000
step: 1800, loss: 0.224922, accuracy: 1.000000
step: 1900, loss: 0.220370, accuracy: 1.000000
step: 2000, loss: 0.185519, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 203.729095, accuracy: 0.226562
step: 200, loss: 195.050644, accuracy: 0.265625
step: 300, loss: 134.021545, accuracy: 0.453125
step: 400, loss: 31.297050, accuracy: 1.000000
step: 500, loss: 7.689310, accuracy: 1.000000
step: 600, loss: 4.364164, accuracy: 1.000000
step: 700, loss: 1.725599, accuracy: 1.000000
step: 800, loss: 1.355214, accuracy: 1.000000
step: 900, loss: 0.967726, accuracy: 1.000000
step: 1000, loss: 0.668614, accuracy: 1.000000
step: 1100, loss: 0.592864, accuracy: 1.000000
step: 1200, loss: 0.540226, accuracy: 1.000000
step: 1300, loss: 0.472330, accuracy: 1.000000
step: 1400, loss: 0.372416, accuracy: 1.000000
step: 1500, loss: 0.322175, accuracy: 1.000000
step: 1600, loss: 0.346084, accuracy: 1.000000
step: 1700, loss: 0.261733, accuracy: 1.000000
step: 1800, loss: 0.265453, accuracy: 1.000000
step: 1900, loss: 0.232169, accuracy: 1.000000
step: 2000, loss: 0.256298, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 203.143982, accuracy: 0.250000
step: 200, loss: 191.845459, accuracy: 0.289062
step: 300, loss: 117.266396, accuracy: 0.710938
step: 400, loss: 31.053202, accuracy: 0.898438
step: 500, loss: 7.111061, accuracy: 1.000000
step: 600, loss: 2.790009, accuracy: 1.000000
step: 700, loss: 1.692702, accuracy: 1.000000
step: 800, loss: 1.370285, accuracy: 1.000000
step: 900, loss: 1.073732, accuracy: 1.000000
step: 1000, loss: 0.730405, accuracy: 1.000000
step: 1100, loss: 0.586712, accuracy: 1.000000
step: 1200, loss: 0.541550, accuracy: 1.000000
step: 1300, loss: 0.475249, accuracy: 1.000000
step: 1400, loss: 0.395153, accuracy: 1.000000
step: 1500, loss: 0.346643, accuracy: 1.000000
step: 1600, loss: 0.344459, accuracy: 1.000000
step: 1700, loss: 0.281113, accuracy: 1.000000
step: 1800, loss: 0.257642, accuracy: 1.000000
step: 1900, loss: 0.220511, accuracy: 1.000000
step: 2000, loss: 0.197841, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 203.455933, accuracy: 0.226562
step: 200, loss: 197.661713, accuracy: 0.242188
step: 300, loss: 115.243561, accuracy: 0.726562
step: 400, loss: 27.418034, accuracy: 0.937500
step: 500, loss: 7.459923, accuracy: 1.000000
step: 600, loss: 2.694706, accuracy: 1.000000
step: 700, loss: 1.989957, accuracy: 1.000000
step: 800, loss: 0.900163, accuracy: 1.000000
step: 900, loss: 0.835827, accuracy: 1.000000
step: 1000, loss: 0.720098, accuracy: 1.000000
step: 1100, loss: 0.567616, accuracy: 1.000000
step: 1200, loss: 0.484167, accuracy: 1.000000
step: 1300, loss: 0.437885, accuracy: 1.000000
step: 1400, loss: 0.393225, accuracy: 1.000000
step: 1500, loss: 0.358784, accuracy: 1.000000
step: 1600, loss: 0.271116, accuracy: 1.000000
step: 1700, loss: 0.258269, accuracy: 1.000000
step: 1800, loss: 0.256022, accuracy: 1.000000
step: 1900, loss: 0.219703, accuracy: 1.000000
step: 2000, loss: 0.200855, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 202.381302, accuracy: 0.257812
step: 200, loss: 194.667023, accuracy: 0.453125
step: 300, loss: 147.874924, accuracy: 0.679688
step: 400, loss: 37.636093, accuracy: 0.843750
step: 500, loss: 4.173418, accuracy: 1.000000
step: 600, loss: 2.320735, accuracy: 1.000000
step: 700, loss: 1.436589, accuracy: 1.000000
step: 800, loss: 1.068983, accuracy: 1.000000
step: 900, loss: 0.880012, accuracy: 1.000000
step: 1000, loss: 0.565943, accuracy: 1.000000
step: 1100, loss: 0.438224, accuracy: 1.000000
step: 1200, loss: 0.458016, accuracy: 1.000000
step: 1300, loss: 0.396886, accuracy: 1.000000
step: 1400, loss: 0.319445, accuracy: 1.000000
step: 1500, loss: 0.325810, accuracy: 1.000000
step: 1600, loss: 0.282217, accuracy: 1.000000
step: 1700, loss: 0.228468, accuracy: 1.000000
step: 1800, loss: 0.228964, accuracy: 1.000000
step: 1900, loss: 0.195556, accuracy: 1.000000
step: 2000, loss: 0.197903, accuracy: 1.000000
Test Accuracy: 1.000000
step: 100, loss: 200.973358, accuracy: 0.265625
step: 200, loss: 192.200928, accuracy: 0.265625
step: 300, loss: 88.483215, accuracy: 0.820312
step: 400, loss: 23.586342, accuracy: 1.000000
step: 500, loss: 5.742866, accuracy: 1.000000
step: 600, loss: 2.722701, accuracy: 1.000000
step: 700, loss: 1.896683, accuracy: 1.000000
step: 800, loss: 1.164479, accuracy: 1.000000
step: 900, loss: 0.810750, accuracy: 1.000000
step: 1000, loss: 0.791417, accuracy: 1.000000
step: 1100, loss: 0.544037, accuracy: 1.000000
step: 1200, loss: 0.560174, accuracy: 1.000000
step: 1300, loss: 0.385581, accuracy: 1.000000
step: 1400, loss: 0.377437, accuracy: 1.000000
step: 1500, loss: 0.340513, accuracy: 1.000000
step: 1600, loss: 0.299393, accuracy: 1.000000
step: 1700, loss: 0.272217, accuracy: 1.000000
step: 1800, loss: 0.254573, accuracy: 1.000000
step: 1900, loss: 0.206227, accuracy: 1.000000
step: 2000, loss: 0.209992, accuracy: 1.000000
Test Accuracy: 1.000000
[0.6000000238418579, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
average accuracy:0.9600000023841858

Process finished with exit code 0