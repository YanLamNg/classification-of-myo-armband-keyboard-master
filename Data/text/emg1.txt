D:\program\Anaconda\envs\comp4190_A2\python.exe C:/Users/Ian/PycharmProjects/comp4190_A2/Code/multilayer_perceptron.py
2020-03-11 13:42:02.054220: I tensorflow/core/platform/cpu_feature_guard.cc:142] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX AVX2
step: 100, loss: 203.648682, accuracy: 0.234375
step: 200, loss: 204.663803, accuracy: 0.234375
step: 300, loss: 201.166473, accuracy: 0.242188
step: 400, loss: 204.310181, accuracy: 0.226562
step: 500, loss: 201.009567, accuracy: 0.281250
step: 600, loss: 203.224823, accuracy: 0.250000
step: 700, loss: 201.031525, accuracy: 0.250000
step: 800, loss: 196.107452, accuracy: 0.289062
step: 900, loss: 187.318512, accuracy: 0.234375
step: 1000, loss: 153.559479, accuracy: 0.460938
step: 1100, loss: 117.059311, accuracy: 0.664062
step: 1200, loss: 87.187012, accuracy: 0.695312
step: 1300, loss: 79.643471, accuracy: 0.710938
step: 1400, loss: 69.882126, accuracy: 0.796875
step: 1500, loss: 55.299133, accuracy: 0.765625
step: 1600, loss: 70.234619, accuracy: 0.750000
step: 1700, loss: 43.322178, accuracy: 0.890625
step: 1800, loss: 65.759377, accuracy: 0.726562
step: 1900, loss: 28.314077, accuracy: 0.937500
step: 2000, loss: 51.407669, accuracy: 0.835938
Test Accuracy: 0.400000
step: 100, loss: 204.944153, accuracy: 0.234375
step: 200, loss: 203.726196, accuracy: 0.234375
step: 300, loss: 204.415359, accuracy: 0.289062
step: 400, loss: 204.437866, accuracy: 0.234375
step: 500, loss: 204.433411, accuracy: 0.210938
step: 600, loss: 203.224991, accuracy: 0.226562
step: 700, loss: 202.256836, accuracy: 0.257812
step: 800, loss: 198.872391, accuracy: 0.351562
step: 900, loss: 206.815155, accuracy: 0.218750
step: 1000, loss: 163.909363, accuracy: 0.460938
step: 1100, loss: 146.970261, accuracy: 0.609375
step: 1200, loss: 121.011703, accuracy: 0.523438
step: 1300, loss: 112.952461, accuracy: 0.632812
step: 1400, loss: 62.044518, accuracy: 0.781250
step: 1500, loss: 72.348228, accuracy: 0.718750
step: 1600, loss: 71.776810, accuracy: 0.718750
step: 1700, loss: 51.667912, accuracy: 0.835938
step: 1800, loss: 137.138336, accuracy: 0.648438
step: 1900, loss: 41.801300, accuracy: 0.914062
step: 2000, loss: 51.768219, accuracy: 0.812500
Test Accuracy: 0.400000
step: 100, loss: 204.944458, accuracy: 0.234375
step: 200, loss: 202.551300, accuracy: 0.273438
step: 300, loss: 203.385315, accuracy: 0.242188
step: 400, loss: 205.325211, accuracy: 0.218750
step: 500, loss: 204.619781, accuracy: 0.265625
step: 600, loss: 202.888794, accuracy: 0.265625
step: 700, loss: 202.209290, accuracy: 0.250000
step: 800, loss: 197.554337, accuracy: 0.257812
step: 900, loss: 191.675079, accuracy: 0.289062
step: 1000, loss: 165.388458, accuracy: 0.398438
step: 1100, loss: 160.317017, accuracy: 0.539062
step: 1200, loss: 110.869118, accuracy: 0.585938
step: 1300, loss: 82.881149, accuracy: 0.750000
step: 1400, loss: 81.525955, accuracy: 0.664062
step: 1500, loss: 55.882187, accuracy: 0.789062
step: 1600, loss: 57.120979, accuracy: 0.867188
step: 1700, loss: 43.743317, accuracy: 0.859375
step: 1800, loss: 67.477928, accuracy: 0.750000
step: 1900, loss: 46.086769, accuracy: 0.898438
step: 2000, loss: 56.470818, accuracy: 0.781250
Test Accuracy: 0.200000
step: 100, loss: 201.218796, accuracy: 0.265625
step: 200, loss: 203.746414, accuracy: 0.226562
step: 300, loss: 204.643158, accuracy: 0.250000
step: 400, loss: 205.582214, accuracy: 0.210938
step: 500, loss: 205.391052, accuracy: 0.210938
step: 600, loss: 203.719116, accuracy: 0.218750
step: 700, loss: 203.472107, accuracy: 0.265625
step: 800, loss: 201.850433, accuracy: 0.312500
step: 900, loss: 198.437408, accuracy: 0.265625
step: 1000, loss: 185.119385, accuracy: 0.320312
step: 1100, loss: 180.166519, accuracy: 0.328125
step: 1200, loss: 146.634567, accuracy: 0.492188
step: 1300, loss: 96.708099, accuracy: 0.593750
step: 1400, loss: 80.359329, accuracy: 0.750000
step: 1500, loss: 82.391029, accuracy: 0.671875
step: 1600, loss: 82.750137, accuracy: 0.765625
step: 1700, loss: 66.758003, accuracy: 0.835938
step: 1800, loss: 82.470108, accuracy: 0.734375
step: 1900, loss: 79.246002, accuracy: 0.773438
step: 2000, loss: 72.335693, accuracy: 0.750000
Test Accuracy: 0.800000
step: 100, loss: 205.223633, accuracy: 0.234375
step: 200, loss: 205.147858, accuracy: 0.226562
step: 300, loss: 200.916122, accuracy: 0.312500
step: 400, loss: 201.492554, accuracy: 0.312500
step: 500, loss: 205.198212, accuracy: 0.226562
step: 600, loss: 202.196167, accuracy: 0.296875
step: 700, loss: 204.221375, accuracy: 0.210938
step: 800, loss: 203.485275, accuracy: 0.242188
step: 900, loss: 199.901581, accuracy: 0.289062
step: 1000, loss: 195.594849, accuracy: 0.398438
step: 1100, loss: 181.920807, accuracy: 0.437500
step: 1200, loss: 202.688507, accuracy: 0.242188
step: 1300, loss: 144.635834, accuracy: 0.460938
step: 1400, loss: 131.912476, accuracy: 0.539062
step: 1500, loss: 96.917160, accuracy: 0.687500
step: 1600, loss: 82.005020, accuracy: 0.781250
step: 1700, loss: 78.907845, accuracy: 0.656250
step: 1800, loss: 77.637741, accuracy: 0.757812
step: 1900, loss: 66.094223, accuracy: 0.796875
step: 2000, loss: 78.530296, accuracy: 0.773438
Test Accuracy: 1.000000
step: 100, loss: 203.656982, accuracy: 0.273438
step: 200, loss: 203.654892, accuracy: 0.273438
step: 300, loss: 204.464828, accuracy: 0.250000
step: 400, loss: 205.298584, accuracy: 0.218750
step: 500, loss: 204.871750, accuracy: 0.234375
step: 600, loss: 204.690918, accuracy: 0.242188
step: 700, loss: 203.858002, accuracy: 0.195312
step: 800, loss: 201.645355, accuracy: 0.257812
step: 900, loss: 196.576630, accuracy: 0.460938
step: 1000, loss: 190.020691, accuracy: 0.210938
step: 1100, loss: 154.100037, accuracy: 0.515625
step: 1200, loss: 123.163185, accuracy: 0.695312
step: 1300, loss: 95.849953, accuracy: 0.703125
step: 1400, loss: 93.950882, accuracy: 0.656250
step: 1500, loss: 109.369400, accuracy: 0.640625
step: 1600, loss: 106.956207, accuracy: 0.617188
step: 1700, loss: 85.764648, accuracy: 0.656250
step: 1800, loss: 72.296494, accuracy: 0.734375
step: 1900, loss: 45.370491, accuracy: 0.859375
step: 2000, loss: 40.335125, accuracy: 0.914062
Test Accuracy: 0.200000
step: 100, loss: 205.447418, accuracy: 0.226562
step: 200, loss: 205.267212, accuracy: 0.226562
step: 300, loss: 205.222260, accuracy: 0.218750
step: 400, loss: 202.976151, accuracy: 0.273438
step: 500, loss: 204.604523, accuracy: 0.234375
step: 600, loss: 203.651703, accuracy: 0.234375
step: 700, loss: 202.475128, accuracy: 0.226562
step: 800, loss: 197.362579, accuracy: 0.265625
step: 900, loss: 196.262924, accuracy: 0.273438
step: 1000, loss: 161.043671, accuracy: 0.398438
step: 1100, loss: 178.042389, accuracy: 0.390625
step: 1200, loss: 132.879120, accuracy: 0.578125
step: 1300, loss: 106.073990, accuracy: 0.640625
step: 1400, loss: 113.494553, accuracy: 0.625000
step: 1500, loss: 85.516502, accuracy: 0.718750
step: 1600, loss: 64.097443, accuracy: 0.757812
step: 1700, loss: 57.014534, accuracy: 0.867188
step: 1800, loss: 49.456123, accuracy: 0.875000
step: 1900, loss: 90.368996, accuracy: 0.703125
step: 2000, loss: 60.158558, accuracy: 0.882812
Test Accuracy: 0.400000
step: 100, loss: 203.670868, accuracy: 0.265625
step: 200, loss: 203.138000, accuracy: 0.226562
step: 300, loss: 203.005341, accuracy: 0.257812
step: 400, loss: 204.136566, accuracy: 0.250000
step: 500, loss: 204.958679, accuracy: 0.226562
step: 600, loss: 204.870667, accuracy: 0.234375
step: 700, loss: 205.276703, accuracy: 0.210938
step: 800, loss: 200.818619, accuracy: 0.273438
step: 900, loss: 202.883514, accuracy: 0.335938
step: 1000, loss: 199.908752, accuracy: 0.234375
step: 1100, loss: 191.479279, accuracy: 0.320312
step: 1200, loss: 171.101578, accuracy: 0.453125
step: 1300, loss: 153.645691, accuracy: 0.421875
step: 1400, loss: 118.747849, accuracy: 0.609375
step: 1500, loss: 110.327850, accuracy: 0.687500
step: 1600, loss: 109.307007, accuracy: 0.609375
step: 1700, loss: 92.973915, accuracy: 0.765625
step: 1800, loss: 111.278976, accuracy: 0.664062
step: 1900, loss: 77.542419, accuracy: 0.679688
step: 2000, loss: 96.573235, accuracy: 0.648438
Test Accuracy: 0.800000
step: 100, loss: 205.010696, accuracy: 0.234375
step: 200, loss: 204.795563, accuracy: 0.234375
step: 300, loss: 205.289398, accuracy: 0.226562
step: 400, loss: 202.323837, accuracy: 0.289062
step: 500, loss: 204.282135, accuracy: 0.234375
step: 600, loss: 202.944687, accuracy: 0.257812
step: 700, loss: 201.830139, accuracy: 0.250000
step: 800, loss: 203.824814, accuracy: 0.320312
step: 900, loss: 199.388153, accuracy: 0.265625
step: 1000, loss: 194.249130, accuracy: 0.390625
step: 1100, loss: 176.446259, accuracy: 0.406250
step: 1200, loss: 141.633530, accuracy: 0.593750
step: 1300, loss: 109.024628, accuracy: 0.671875
step: 1400, loss: 77.974525, accuracy: 0.773438
step: 1500, loss: 87.307556, accuracy: 0.609375
step: 1600, loss: 76.842148, accuracy: 0.726562
step: 1700, loss: 89.492615, accuracy: 0.734375
step: 1800, loss: 67.887550, accuracy: 0.703125
step: 1900, loss: 73.357742, accuracy: 0.726562
step: 2000, loss: 50.265266, accuracy: 0.851562
Test Accuracy: 0.800000
step: 100, loss: 200.024597, accuracy: 0.281250
step: 200, loss: 204.151260, accuracy: 0.265625
step: 300, loss: 203.073517, accuracy: 0.257812
step: 400, loss: 204.916077, accuracy: 0.257812
step: 500, loss: 205.555542, accuracy: 0.210938
step: 600, loss: 204.037567, accuracy: 0.250000
step: 700, loss: 202.867584, accuracy: 0.265625
step: 800, loss: 202.332275, accuracy: 0.507812
step: 900, loss: 202.179657, accuracy: 0.273438
step: 1000, loss: 197.307968, accuracy: 0.273438
step: 1100, loss: 191.309570, accuracy: 0.281250
step: 1200, loss: 189.946152, accuracy: 0.234375
step: 1300, loss: 125.572960, accuracy: 0.562500
step: 1400, loss: 179.488968, accuracy: 0.382812
step: 1500, loss: 81.133530, accuracy: 0.617188
step: 1600, loss: 70.340729, accuracy: 0.765625
step: 1700, loss: 73.526146, accuracy: 0.781250
step: 1800, loss: 85.657272, accuracy: 0.664062
step: 1900, loss: 63.375935, accuracy: 0.804688
step: 2000, loss: 54.948715, accuracy: 0.843750
Test Accuracy: 0.600000
[0.4000000059604645, 0.4000000059604645, 0.20000000298023224, 0.800000011920929, 1.0, 0.20000000298023224, 0.4000000059604645, 0.800000011920929, 0.800000011920929, 0.6000000238418579]
average accuracy:0.5600000083446502